{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Configure GPU \n",
    "gpu_num = 1 # Use \"\" to use the CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Import Sionna\n",
    "import sionna\n",
    "sionna.config.xla_compat=True \n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "# Set global random seed for reproducibility\n",
    "            \n",
    "import numpy as np\n",
    "import sionna.rt as rt\n",
    "from sionna.constants import PI\n",
    "from sionna.channel import cir_to_ofdm_channel\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e) \n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mode as f2f for reproducing Fig.3, f2s for Fig.4, s2f for Fig.5 respectively.\n",
    "mode = \"s2f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set scatterers\n",
    "scatter_infos = []\n",
    "\n",
    "# scatter modeling by PCA\n",
    "# scatterer 0\n",
    "mat_type_table = np.ones([10, 10])\n",
    "for ii in range(3):\n",
    "    for jj in range(ii+1):\n",
    "        mat_type_table[(ii*3+1):(ii*3+3), ((jj)*3+1):(jj*3+3)] = 0\n",
    "mat_type_table = tf.convert_to_tensor(mat_type_table, dtype=tf.int32)\n",
    "roughness = tf.convert_to_tensor([10, 1e-3])\n",
    "em_prop = tf.convert_to_tensor([tf.complex(6.31, -0.26), tf.complex(5.24, -0.34)])\n",
    "roughness_table, em_prop_table = utils.Scatter_info.gen_table(mat_type_table, roughness, em_prop)\n",
    "tile_length = 3.06\n",
    "tile_width = 3.06\n",
    "transform = tf.convert_to_tensor([[0., 0., 0.], [0., 0., 0.]])\n",
    "scatter_infos.append(utils.Scatter_info(roughness_table, em_prop_table, tile_length, tile_width, transform))\n",
    "\n",
    "#scatterer 1\n",
    "mat_type_table = np.ones([5, 5])\n",
    "for ii in range(5):\n",
    "    for jj in range(ii+1):\n",
    "        mat_type_table[ii,jj] = 0\n",
    "mat_type_table = tf.convert_to_tensor(mat_type_table, dtype=tf.int32)\n",
    "roughness = tf.convert_to_tensor([10, 1e-3])\n",
    "em_prop = tf.convert_to_tensor([tf.complex(6.31, -0.26), tf.complex(5.24, -0.34)])\n",
    "roughness_table, em_prop_table = utils.Scatter_info.gen_table(mat_type_table, roughness, em_prop)\n",
    "tile_length = 3\n",
    "tile_width = 3\n",
    "transform = tf.convert_to_tensor([[7., 18., 9.], [0., 0., -PI/2]])\n",
    "scatter_infos.append(utils.Scatter_info(roughness_table, em_prop_table, tile_length, tile_width, transform))\n",
    "\n",
    "#scatterer 2\n",
    "mat_type_table = np.ones([5, 5])\n",
    "for ii in range(5):\n",
    "    for jj in range(ii+1):\n",
    "        mat_type_table[ii,jj] = 0\n",
    "mat_type_table = tf.convert_to_tensor(mat_type_table, dtype=tf.int32)\n",
    "roughness = tf.convert_to_tensor([10, 1e-3])\n",
    "em_prop = tf.convert_to_tensor([tf.complex(6.31, -0.26), tf.complex(5.24, -0.34)])\n",
    "roughness_table, em_prop_table = utils.Scatter_info.gen_table(mat_type_table, roughness, em_prop)\n",
    "tile_length = 3\n",
    "tile_width = 3\n",
    "transform = tf.convert_to_tensor([[-7., -18., 9.], [0., 0., PI/2]])\n",
    "scatter_infos.append(utils.Scatter_info(roughness_table, em_prop_table, tile_length, tile_width, transform))\n",
    "\n",
    "# sequence: elm_2, elm_6, elm_8\n",
    "scatter_labels = ['elm__2','elm__6','elm__8']\n",
    "scatter_ids = []\n",
    "\n",
    "scene = rt.load_scene(\"./scene/multiple_scatters/multiple_scatters.xml\")\n",
    "for ii in range(len(scatter_labels)):\n",
    "    scatter_ids.append(scene.objects[scatter_labels[ii]].object_id)\n",
    "\n",
    "id_hash = np.ones(max(scatter_ids) + 1) * -1\n",
    "for ii in range(len(scatter_labels)):\n",
    "    id_hash[scene.objects[scatter_labels[ii]].object_id] = ii\n",
    "id_hash = tf.convert_to_tensor(id_hash, dtype=tf.int32)\n",
    "\n",
    "em_property = utils.Em_property(scatter_infos, id_hash)\n",
    "\n",
    "scene.frequency = 3e9\n",
    "scene.radio_material_callable = utils.Radio_material(em_property=em_property)\n",
    "scene.scattering_pattern_callable = utils.Scatter(em_property=em_property)\n",
    "tx_antenna_num = 4\n",
    "rx_antenna_num = 4\n",
    "\n",
    "scene.tx_array = rt.PlanarArray(num_rows=tx_antenna_num, num_cols=1, \n",
    "                                vertical_spacing=0.5, \n",
    "                                horizontal_spacing=0.5, \n",
    "                                pattern=\"hw_dipole\", \n",
    "                                polarization=\"V\")\n",
    "scene.rx_array = rt.PlanarArray(num_rows=rx_antenna_num, num_cols=1, \n",
    "                                vertical_spacing=0.5, \n",
    "                                horizontal_spacing=0.5, \n",
    "                                pattern=\"hw_dipole\", \n",
    "                                polarization=\"V\")\n",
    "\n",
    "scene.add(rt.Transmitter(name=\"Tx\", \n",
    "                         position=[-50, 0, 50], \n",
    "                         orientation=[0, PI/4, 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW = 150e6\n",
    "num_freq = 11\n",
    "frequencies = np.linspace(scene.frequency - 0.5 * BW, scene.frequency + 0.5 * BW, num_freq)\n",
    "frequencies = tf.convert_to_tensor(frequencies)\n",
    "frequencies = tf.cast(frequencies, tf.float32)\n",
    "noise = 1e-9\n",
    "SNR = 1 / noise\n",
    "\n",
    "train_size = 2000\n",
    "cube_length = 3\n",
    "random_phase = True\n",
    "#specify the antenna id used to calibrate roughness parameter\n",
    "tx_for_train = 0\n",
    "rx_for_train = 0\n",
    "#specify the subcarrier id used to calibrate roughness parameter\n",
    "sc_for_train = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train set in Ωtrain\n",
    "theta = 2 * PI / 3 * np.random.rand() + PI * 6\n",
    "height_shift = 6 * np.random.rand() - 3\n",
    "\n",
    "train_position = [9.38, 7.32, 2.40]\n",
    "\n",
    "for keys in scene.receivers:\n",
    "    scene.remove(keys)\n",
    "for jj in range(train_size):\n",
    "    Rx_pos = cube_length * np.random.rand(3) + np.array(train_position)\n",
    "    scene.add(rt.Receiver(name=f\"Rx_{jj}\", position=Rx_pos, orientation=[0, -PI/4, 0]))\n",
    "paths = scene.compute_paths(check_scene=False, \n",
    "                                    num_samples=1e5,\n",
    "                                    los=False,\n",
    "                                    reflection=False, \n",
    "                                    scattering=True, \n",
    "                                    scat_random_phases=random_phase, \n",
    "                                    scat_keep_prob=1)\n",
    "\n",
    "h_f = cir_to_ofdm_channel(frequencies, paths.a, paths.tau)\n",
    "\n",
    "# When calculating CCM, we only consider the correlation between one of Tx antennas/ Rx antennas/ subcarriers\n",
    "# at one time, so the other two need to be specified.\n",
    "\n",
    "if mode[0] == 'f':\n",
    "    h_f = tf.squeeze(tf.squeeze(h_f)[:,rx_for_train,tx_for_train,:])\n",
    "else:\n",
    "    h_f = tf.squeeze(tf.squeeze(h_f)[:,:,tx_for_train,sc_for_train])\n",
    "\n",
    "R_hf = tf.matmul(tf.transpose(h_f, conjugate=True), h_f) / train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate test set in Ωtest\n",
    "theta = 2 * PI / 3 * np.random.rand() + PI * 6\n",
    "height_shift = 6 * np.random.rand() - 3\n",
    "\n",
    "test_position = [3.76, 11.30, 4.71]\n",
    "\n",
    "for keys in scene.receivers:\n",
    "    scene.remove(keys)\n",
    "for jj in range(train_size):\n",
    "    Rx_pos = cube_length * np.random.rand(3) + np.array(test_position)\n",
    "    scene.add(rt.Receiver(name=f\"Rx_{jj}\", position=Rx_pos, orientation=[0, -PI/4, 0]))\n",
    "paths = scene.compute_paths(check_scene=False, \n",
    "                                    num_samples=1e5,\n",
    "                                    los=False,\n",
    "                                    reflection=False, \n",
    "                                    scattering=True, \n",
    "                                    scat_random_phases=random_phase, \n",
    "                                    scat_keep_prob=1)\n",
    "\n",
    "h_f = cir_to_ofdm_channel(frequencies, paths.a, paths.tau)\n",
    "# When calculating CCM, we only consider the correlation between one of Tx antennas/ Rx antennas/ subcarriers\n",
    "# at one time, so the other two need to be specified.\n",
    "\n",
    "if mode[2] == 'f':\n",
    "    h_f = tf.squeeze(tf.squeeze(h_f)[:,rx_for_train,tx_for_train,:])\n",
    "else:\n",
    "    h_f = tf.squeeze(tf.squeeze(h_f)[:,:,tx_for_train,sc_for_train])\n",
    "R_hf_test = tf.matmul(tf.transpose(h_f, conjugate=True), h_f) / train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cal corrmat for learning\n",
    "scatter_infos = []\n",
    "R_list = []\n",
    "v_list = []\n",
    "# scatterer 0 \n",
    "scatter_length = 30.6\n",
    "scatter_width = 30.6\n",
    "corr_len = 4\n",
    "transform = tf.convert_to_tensor([[0., 0., 0.], [0., 0., 0.]])\n",
    "\n",
    "tile_row, tile_colomn, tile_length, tile_width = utils.cal_size(scatter_length, scatter_width, corr_len)\n",
    "R0, v0 = utils.cal_R(tile_row, tile_colomn, tile_length, tile_width, corr_len)\n",
    "roughness_table = 15 * tf.sigmoid(tf.reshape(tf.matmul(R0, v0, transpose_b=True), (tile_row, tile_colomn)))\n",
    "em_prop_table = tf.ones_like(roughness_table, dtype=tf.complex64) * tf.complex(5.2, -0.2)\n",
    "scatter_infos.append(utils.Scatter_info(roughness_table, em_prop_table, tile_length, tile_width, transform))\n",
    "R_list.append(R0)\n",
    "v_list.append(v0)\n",
    "\n",
    "# scatter 1\n",
    "scatter_length = 15\n",
    "scatter_width = 15\n",
    "corr_len = 3\n",
    "transform = tf.convert_to_tensor([[7., 18., 9.], [0., 0., -PI/2]])\n",
    "\n",
    "tile_row, tile_colomn, tile_length, tile_width = utils.cal_size(scatter_length, scatter_width, corr_len)\n",
    "R1, v1 = utils.cal_R(tile_row, tile_colomn, tile_length, tile_width, corr_len)\n",
    "roughness_table = 15 * tf.sigmoid(tf.reshape(tf.matmul(R1, v1, transpose_b=True), (tile_row, tile_colomn)))\n",
    "em_prop_table = tf.ones_like(roughness_table, dtype=tf.complex64) * tf.complex(5.2, -0.2)\n",
    "scatter_infos.append(utils.Scatter_info(roughness_table, em_prop_table, tile_length, tile_width, transform))\n",
    "R_list.append(R1)\n",
    "v_list.append(v1)\n",
    "\n",
    "# scatterer 2 \n",
    "scatter_length = 15\n",
    "scatter_width = 15\n",
    "corr_len = 3\n",
    "transform = tf.convert_to_tensor([[-7., -18., 9.], [0., 0., PI/2]])\n",
    "\n",
    "tile_row, tile_colomn, tile_length, tile_width = utils.cal_size(scatter_length, scatter_width, corr_len)\n",
    "R2, v2 = utils.cal_R(tile_row, tile_colomn, tile_length, tile_width, corr_len)\n",
    "roughness_table = 15 * tf.sigmoid(tf.reshape(tf.matmul(R2, v2, transpose_b=True), (tile_row, tile_colomn)))\n",
    "em_prop_table = tf.ones_like(roughness_table, dtype=tf.complex64) * tf.complex(5.2, -0.2)\n",
    "scatter_infos.append(utils.Scatter_info(roughness_table, em_prop_table, tile_length, tile_width, transform))\n",
    "R_list.append(R2)\n",
    "v_list.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(scatter_labels)):\n",
    "    scatter_ids.append(scene.objects[scatter_labels[ii]].object_id)\n",
    "\n",
    "id_hash = np.ones(max(scatter_ids) + 1) * -1\n",
    "for ii in range(len(scatter_labels)):\n",
    "    id_hash[scene.objects[scatter_labels[ii]].object_id] = ii\n",
    "id_hash = tf.convert_to_tensor(id_hash, dtype=tf.int32)\n",
    "\n",
    "em_property = utils.Em_property(scatter_infos, id_hash)\n",
    "\n",
    "scene.radio_material_callable = utils.Radio_material(em_property=em_property)\n",
    "scene.scattering_pattern_callable = utils.Scatter(em_property=em_property)\n",
    "\n",
    "batch_size = 1000\n",
    "if mode[0] == 'f':\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=2e4)\n",
    "else:\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=2e13)\n",
    "test_loss = []\n",
    "train_loss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate paths in advance to reduce time consumption\n",
    "for keys in scene.receivers:\n",
    "    scene.remove(keys)\n",
    "for jj in range(batch_size):\n",
    "    Rx_pos = cube_length * np.random.rand(3) + np.array(train_position)\n",
    "    scene.add(rt.Receiver(name=f\"Rx_{jj}\", position=Rx_pos, orientation=[0, -PI/4, 0]))\n",
    "traced_paths_train = scene.trace_paths(check_scene=False, \n",
    "                                        num_samples=1e5,\n",
    "                                        los=False,\n",
    "                                        reflection=False, \n",
    "                                        scattering=True, \n",
    "                                        scat_keep_prob=1)\n",
    "\n",
    "for keys in scene.receivers:\n",
    "    scene.remove(keys)\n",
    "for jj in range(batch_size):\n",
    "    Rx_pos = cube_length * np.random.rand(3) + np.array(test_position)\n",
    "    scene.add(rt.Receiver(name=f\"Rx_{jj}\", position=Rx_pos, orientation=[0, -PI/4, 0]))\n",
    "traced_paths_test = scene.trace_paths(check_scene=False, \n",
    "                                    num_samples=1e5,\n",
    "                                    los=False,\n",
    "                                    reflection=False, \n",
    "                                    scattering=True, \n",
    "                                    scat_keep_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "if mode == \"f2f\":\n",
    "    num_of_iter = 50\n",
    "elif mode == \"f2s\":\n",
    "    num_of_iter = 200\n",
    "elif mode == \"s2f\":\n",
    "    num_of_iter = 150\n",
    "for ii in range(num_of_iter):\n",
    "    \n",
    "    paths = scene.compute_fields(*traced_paths_test,\n",
    "                                    check_scene=False,\n",
    "                                    scat_random_phases=True)\n",
    "    h_f = sionna.channel.cir_to_ofdm_channel(frequencies, paths.a, paths.tau) \n",
    "    if mode[2] == 'f':\n",
    "        h_f = tf.squeeze(tf.squeeze(h_f)[:,rx_for_train,tx_for_train,:])\n",
    "    else:\n",
    "        h_f = tf.squeeze(tf.squeeze(h_f)[:,:,tx_for_train,sc_for_train])\n",
    "    R_hf_hat = tf.matmul(tf.transpose(h_f, conjugate=True), h_f) / batch_size  \n",
    "\n",
    "    #loss function for extrapolation in frequency domain\n",
    "    if mode[2] == 'f':\n",
    "        I = tf.eye(R_hf_hat.shape[0], dtype=tf.complex64)\n",
    "        R_y_hat = R_hf_hat + I / SNR\n",
    "        R_y = R_hf_test + I / SNR\n",
    "        diff = tf.linalg.inv(R_y_hat) - tf.linalg.inv(R_y)\n",
    "        loss = tf.linalg.trace(R_y @ diff @ diff) / (SNR ** 2)\n",
    "        loss = tf.math.real(loss)\n",
    "    else:\n",
    "        loss = tf.reduce_mean(tf.square(tf.abs(R_hf_hat - R_hf_test)))\n",
    "    #Set loss function to be MSE for extrapolation in spatial domain\n",
    "    \n",
    "    test_loss.append(loss.numpy())\n",
    "    print(f\"test loss={loss}\")\n",
    "            \n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \n",
    "        roughness_table_list = []\n",
    "        for ii in range(len(v_list)):\n",
    "            temp = 15 * tf.sigmoid(tf.reshape(tf.matmul(R_list[ii], v_list[ii], transpose_b=True),\n",
    "                                            scatter_infos[ii].roughness_table.shape))\n",
    "            roughness_table_list.append(temp)\n",
    "\n",
    "        em_property.update_roughness(roughness_table_list)\n",
    "\n",
    "        paths = scene.compute_fields(*traced_paths_train,\n",
    "                                    check_scene=False,\n",
    "                                    scat_random_phases=False)\n",
    "        h_f = sionna.channel.cir_to_ofdm_channel(frequencies, paths.a, paths.tau) \n",
    "        if mode[0] == 'f':\n",
    "            h_f = tf.squeeze(tf.squeeze(h_f)[:,rx_for_train,tx_for_train,:])\n",
    "        else:\n",
    "            h_f = tf.squeeze(tf.squeeze(h_f)[:,:,tx_for_train,sc_for_train])\n",
    "        \n",
    "        R_hf_hat = tf.matmul(tf.transpose(h_f, conjugate=True), h_f) / batch_size\n",
    "\n",
    "        if mode[0] == 'f':\n",
    "            I = tf.eye(R_hf_hat.shape[0], dtype=tf.complex64)\n",
    "            R_y_hat = R_hf_hat + I / SNR\n",
    "            R_y = R_hf + I / SNR\n",
    "            diff = tf.linalg.inv(R_y_hat) - tf.linalg.inv(R_y)\n",
    "            loss = tf.linalg.trace(R_y @ diff @ diff) / (SNR ** 2)\n",
    "            loss = tf.math.real(loss)\n",
    "        else:\n",
    "            loss = tf.reduce_mean(tf.square(tf.abs(R_hf_hat - R_hf)))\n",
    "\n",
    "        train_loss.append(loss.numpy())\n",
    "        print(f\"                                  train loss={loss}\")\n",
    "\n",
    "        dv = tape.gradient(loss, v_list)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(dv, v_list))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curve\n",
    "\n",
    "plt.rc('font',family='Times New Roman')\n",
    "fig, ax_train = plt.subplots()\n",
    "ax_test = ax_train.twinx()\n",
    "\n",
    "yticks = [float(format(x, '.3g')) for x in np.linspace(min(train_loss), max(train_loss), 8)]\n",
    "ax_train.set_yticks(yticks)\n",
    "yticks = [float(format(x, '.3g')) for x in np.linspace(min(test_loss), max(test_loss), 8)]\n",
    "ax_test.set_yticks(yticks)\n",
    "\n",
    "iteration = np.linspace(0,len(train_loss), len(train_loss))\n",
    "line_train, = ax_train.plot(iteration, np.array(train_loss), color=(0.26,0.55,1), label=\"train loss\")\n",
    "line_test, = ax_test.plot(iteration, np.array(test_loss), color=\"orange\", label=\"test loss\")\n",
    "\n",
    "lines = [line_train, line_test]\n",
    "labels = [line.get_label() for line in lines]\n",
    "legend = ax_train.legend(lines, labels, loc=0, bbox_to_anchor=(1, 0.95), frameon=True, facecolor='white', edgecolor='black')\n",
    "legend.get_frame().set_alpha(1)\n",
    "\n",
    "\n",
    "ax_train.grid(axis='both')\n",
    "\n",
    "if mode == \"f2f\":\n",
    "    plt.title(r\"Extrapolation: Frequency Domain To Frequency Domain\" + \"\\n\\n\" + \\\n",
    "            \"train loss=$\\mathscr{L}_1$                          test loss=$\\mathscr{L}_1$\")\n",
    "elif mode == \"f2s\":\n",
    "    plt.title(r\"Extrapolation: Frequency Domain To Spatial Domain\" + \"\\n\\n\" + \\\n",
    "            \"train loss=$\\mathscr{L}_1$                          test loss=$\\mathscr{L}_2$\")\n",
    "elif mode == \"s2f\":\n",
    "    plt.title(r\"Extrapolation: Spatial Domain To Frequency Domain\" + \"\\n\\n\" + \\\n",
    "            \"train loss=$\\mathscr{L}_2$                          test loss=$\\mathscr{L}_1$\")\n",
    "\n",
    "ax_train.set_xlabel(\"Number of iteration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
